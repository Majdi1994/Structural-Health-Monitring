{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "#from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as ptl\n",
    "from utils import MyDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoolModel(ptl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(CoolModel, self).__init__()\n",
    "        self.data_dir='data/train_test_dataset_1024.pt'\n",
    "        self.my_data = torch.load(self.data_dir)\n",
    "        # not the best model...\n",
    "        self.hidden_dim = 30\n",
    "        self.input_dim = 1\n",
    "        self.dropout=0.5\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(self.input_dim, 8, kernel_size=7, stride=1, padding=1, dilation=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(8, 8, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(8, 8, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(8, 8, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(8, 8, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(8, 8, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, self.hidden_dim))\n",
    "        self.Classifier= nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim//2) ,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(self.hidden_dim//2, 11))\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, src):\n",
    "        features = self.encoder(src)\n",
    "        predictions = self.Classifier(features)\n",
    "        return predictions, features\n",
    "\n",
    "    def my_loss(self, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return {'loss': self.my_loss(y_hat, y)}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return {'val_loss': self.my_loss(y_hat, y)}\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        return {'avg_val_loss': avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return [torch.optim.Adam(self.parameters(), lr=0.02)]\n",
    "\n",
    "    @ptl.data_loader\n",
    "    def tng_dataloader(self):\n",
    "        data= self.my_data['train_data'],  self.my_data['train_labels']\n",
    "        dataset = MyDataset(data)\n",
    "        return torch.utils.DataLoader(dataset, batch_size=10, shuffle=True, drop_last=True)\n",
    "\n",
    "    @ptl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    @ptl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        test_dl = DataLoader(MyDataset(self.my_data['test_data'],  self.my_data['test_labels']), batch_size=10, shuffle=False, drop_last=False)\n",
    "        return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-51e46e17279b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 3 START TRAINING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myphd_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;31m# return 1 when finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myphd_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# transfer data loaders from model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[1;31m# print model summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myphd_env\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py\u001b[0m in \u001b[0;36mget_dataloaders\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_train_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_test_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_val_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myphd_env\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py\u001b[0m in \u001b[0;36minit_train_dataloader\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# determine number of training batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mEXIST_ITER_DATASET\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_train_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_training_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "    trainer = ptl.Trainer()\n",
    "    model = CoolModel()\n",
    "    # ------------------------\n",
    "    # 3 START TRAINING\n",
    "    # ------------------------\n",
    "    trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
